#include "guestlib/extensions/guest_cmd_batching_queue.h"

#include <absl/functional/bind_front.h>
#include <glib.h>

#include <gsl/gsl>
#include <memory>

#include "common/cmd_channel.hpp"
#include "common/common_context.h"
#include "common/declaration.h"
#include "common/endpoint_lib.hpp"
#include "common/extensions/cmd_batching.h"
#include "common/logging.h"
#include "common/shadow_thread_pool.hpp"
#include "guestlib/guest_thread.h"

/**
 * batch_emit - Emit batched commands to the API server
 * @active_cmds: the commands to be emitted
 */
static void batch_emit(GAsyncQueue *active_cmds) {
  ava_debug("Emit a batch with %u commands\n", g_async_queue_length(active_cmds));

  GQueue *queue = g_queue_new();
  size_t __total_buffer_size = 0;
  {
    gpointer cmd;
    while ((cmd = g_async_queue_try_pop(active_cmds))) {
      g_queue_push_head(queue, cmd);
      __total_buffer_size += ((struct command_base *)cmd)->command_size + ((struct command_base *)cmd)->region_size;
    }
  }

  void *__command_buffer = malloc(__total_buffer_size);
  {
    off_t offset = 0;
    struct command_base *cmd;
    while ((cmd = (struct command_base *)g_queue_pop_tail(queue))) {
      memcpy((char *)__command_buffer + offset, (void *)cmd, cmd->command_size + cmd->region_size);
      offset += cmd->command_size + cmd->region_size;
      free(cmd);
    }
    assert(gsl::narrow_cast<size_t>(offset) == __total_buffer_size);
  }

  /* __do_batch_emit is generated by AvA. */
  __do_batch_emit(__command_buffer, __total_buffer_size);

  free(__command_buffer);
  g_queue_free(queue);
}

struct command_wrapper {
  struct command_base *cmd;
  struct command_channel *chan;
  int is_async;
};

namespace ava {

GuestCmdBatchingQueue::GuestCmdBatchingQueue()
    : cmd_batching_thread_("GuestCmdBatchingQueue",
                           absl::bind_front(&GuestCmdBatchingQueue::CmdBatchingThreadMain, this)) {
  pending_cmds_ = g_async_queue_new_full((GDestroyNotify)free);
  active_cmds_ = g_async_queue_new_full((GDestroyNotify)free);
}

GuestCmdBatchingQueue::~GuestCmdBatchingQueue() {
  g_async_queue_unref(active_cmds_);
  // FIXME: g_async_queue_unref: assertion 'queue->waiting_threads == 0' failed
  // g_async_queue_unref(pending_cmds_);
}

void GuestCmdBatchingQueue::Start() { cmd_batching_thread_.Start(); }

void GuestCmdBatchingQueue::Stop() {
  running_ = false;
  cmd_batching_thread_.Cancel();
  cmd_batching_thread_.Join();
}

/**
 * enqueue - Insert a new command to the batch
 * @cmd: command to be inserted to the batch
 * @chan: channel to emit the command
 * @is_async: whether this command is asynchronous or not
 *
 * When the batched commands reach the maximum batch size, we emit the batch to
 * the API server.
 */
void GuestCmdBatchingQueue::enqueue_cmd(::command_base *cmd, ::command_channel *chan, bool is_async) {
  struct command_wrapper *wrap = reinterpret_cast<struct command_wrapper *>(g_malloc(sizeof(struct command_wrapper)));
  wrap->cmd = cmd;
  wrap->chan = chan;
  wrap->is_async = is_async;

  ava_debug("Add command (%ld) to pending batched command list\n", cmd->command_id);
  g_async_queue_push(pending_cmds_, (gpointer)wrap);
}

void GuestCmdBatchingQueue::CmdBatchingThreadMain() {
  struct command_wrapper *wrap;
  gdouble elapsed_time;
  GTimer *timer = g_timer_new();
  auto common_ctx = ava::CommonContext::instance();
  int64_t thread_id = shadow_thread_id(common_ctx->nw_shadow_thread_pool);

  running_ = true;
  if (pthread_setcancelstate(PTHREAD_CANCEL_ENABLE, NULL)) {
    perror("pthread_setcancelstate failed\n");
    exit(0);
  }
  if (pthread_setcanceltype(PTHREAD_CANCEL_ASYNCHRONOUS, NULL)) {
    perror("pthread_setcanceltype failed\n");
    exit(0);
  }

  fprintf(stderr, "Start batch processing thread\n");
  g_timer_start(timer);

  while (running_) {
    wrap = (struct command_wrapper *)g_async_queue_timeout_pop(pending_cmds_, (BATCH_QUEUE_TIME_OUT_US));

    if (!running_) break;

    /* Special case:
     * cuCtxSetCurrent must be inserted to the batch to set the correct CUDA context for the
     * shadow thread of batch processing thread.
     *
     * Current solution is to set the emitted synchronous command's thread id to the batch
     * processing thread's.
     */

    /* Emit the single synchronous API. */
    if (wrap && !wrap->is_async && g_async_queue_length(active_cmds_) == 0) {
      ava_debug("Emit a synchronous command %ld, thread id %lx->%lx\n", wrap->cmd->command_id, wrap->cmd->thread_id,
                thread_id);
      wrap->cmd->thread_id = thread_id;
      command_channel_send_command(wrap->chan, wrap->cmd);
      g_free(wrap);
      g_timer_start(timer);
      continue;
    }

    if (wrap) g_async_queue_push(active_cmds_, (gpointer)wrap->cmd);

    /* Emit the batch when there is a synchronous API, or we have enough commands in the batch,
     * or it has been a while (10ms) since last emit. */
    g_timer_stop(timer);
    elapsed_time = g_timer_elapsed(timer, NULL);
    if ((wrap && !wrap->is_async) || g_async_queue_length(active_cmds_) >= BATCH_SIZE ||
        elapsed_time >= BATCH_TIME_OUT_US) {
      if (wrap && !wrap->is_async) {
        ava_debug("Emit a batch ending with a synchronous command %ld\n", wrap->cmd->command_id);
      }

      batch_emit(active_cmds_);
      g_timer_start(timer);
    } else {
      g_timer_continue(timer);
    }

    if (wrap) g_free(wrap);
  }

  g_timer_destroy(timer);

  return NULL;
}

}  // namespace ava
